{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "98106434 <span style='font-size:larger;'>→</span> Mohammad Khodadadi Aski\n",
    "<br>\n",
    "98105919 <span style='font-size:larger;'>→</span> Reza Erfan Arani\n",
    "<br>\n",
    "98101566 <span style='font-size:larger;'>→</span> Mohammadreza Daviran\n",
    "<br>\n",
    "<br>\n",
    "<a href='https://github.com/rerfan24/MIR-HW1' style='text-align:center;'>github repo</a> \n",
    "<br>\n",
    "\n",
    "\n",
    "We use the BeautifulSoup in order to extraxt data from the request we send to the website .\n",
    ".strip method removes any unexpected and useless whitespace\n",
    "In order to run the code , you should run the bellow cell to installl required libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install hazm\n",
    "!pip install selenium\n",
    "!pip install bs4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the code bellow we do the following tasks:\n",
    "<br>\n",
    "Normalization :\n",
    "<br>\n",
    "In normalization we delete the spaces which dont have any meaning .\n",
    "<br>\n",
    "Tokenized_sent_input <span style='font-size:larger;'>→</span> We use the sent_tokenize method of hazm library in order to tokenize the sentences of our input.\n",
    "<br>\n",
    "Tokenized_word_input <span style='font-size:larger;'>→</span> We use the word_tokenize method of hazm library to tokenize our input word by word.\n",
    "<br>\n",
    "Then we stem our normlized input in order to send the words to their root word, but we dont use it in this project because of our tasks which we can afford loosing any data.\n",
    "<br>\n",
    "We have the same thing with the lemmatizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals\n",
    "from hazm import *\n",
    "\n",
    "def run (input:str):\n",
    "    normalizer = Normalizer()\n",
    "    normilized_input=normalizer.normalize(input)\n",
    "    tokenized_sent_input = sent_tokenize(input)\n",
    "    tokenized_word_input = word_tokenize(input)\n",
    "    stemmer = Stemmer()\n",
    "    stemmed_input = stemmer.stem(normilized_input)\n",
    "    # we did this , but we shouldnt use this data cause some data are lost during this pre-proccessing phase\n",
    "    print(f'{tokenized_sent_input}\\n{tokenized_word_input}')\n",
    "    indices = [i for i, x in enumerate(tokenized_word_input) if x.startswith('دستور')]\n",
    "    print(indices)\n",
    "    lemmatizer = Lemmatizer()\n",
    "    lemmed_input = lemmatizer.lemmatize(normilized_input)\n",
    "    # we also have the same thing about lemmatizing (same as stemming)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following function, we extracted recipe from the data using the index given."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_recipe(input_recipe, index):\n",
    "    recipe = input_recipe[index:]\n",
    "    newline_index = recipe.index(chr(10)) \n",
    "    recipe = recipe[newline_index + 1:]\n",
    "    return recipe, [index + newline_index + 1, len(input_recipe)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following code block, we find the spans of different ingredients, in order to do so we search our data string and find the ingredient given in the text and we return the starting index and ending index of each ingredient in the given text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findSpanIngredient(ingut: str, ingredients):\n",
    "    span = []\n",
    "    last = 0\n",
    "    for ing in ingredients:\n",
    "        try: \n",
    "            first = ingut.index(ing)\n",
    "        except:\n",
    "            first = last + 1\n",
    "        while (last <= first):\n",
    "            last = ingut.index(chr(10),last+1)\n",
    "        if (not ingut[first:last].startswith('دستور شمار')):\n",
    "            span.append([first,last])\n",
    "    return span"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code block is written to find ingredients in our string. <br>\n",
    "We split our text by 3 splitors, each showing a specific data part in our input string. <br>\n",
    "We use our spliter array which contains the amounts in both numbers and uncountable quantities to split data one more time so that we could extract amount for each ingredient seprately. from start of the line to our splitter index will be our ingredient and from our ingredient index to the end of the line will be our ingredient amount."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_ingredients(ingut : str):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    ingredients = []\n",
    "    quantity = []\n",
    "    span_ingredients = []\n",
    "    if \"مواد\" in ingut.split(\"\\n\")[0]:\n",
    "        starting_index = ingut.index(\"مواد\")\n",
    "    else:\n",
    "        starting_index = 0\n",
    "    prepare_spliter = [\"طرز تهیه\", \"روش تهیه\", \"طرزتهیه\"]\n",
    "    ending_index = 0\n",
    "    for element in prepare_spliter:\n",
    "            try:\n",
    "                ending_index = ingut.index(element)\n",
    "                break\n",
    "            except:\n",
    "                continue\n",
    "    \n",
    "    ing_data = ingut[starting_index:ending_index]\n",
    "    if \"مواد\" in ingut.split(\"\\n\")[0]:\n",
    "        ing_data= ing_data.split(\"\\n\",1)[1]\n",
    "    if \"مواد\" in ingut.split(\"\\n\")[1]:\n",
    "        ing_data= ing_data.split(\"\\n\",1)[1]\n",
    "        ing_data= ing_data.split(\"\\n\",1)[1]\n",
    "        \n",
    "    spliter = ['0', '۰','1', '۱', '2', '۲', '3', '۳', '4', '۴', '5', '۵', '6',\n",
    "               '۶', '7', '۷', '8', '۸', '9', '۹', 'یک ', 'یک‌',\n",
    "               'دو ', 'دو‌', 'سه ', 'سه‌','نیم', 'نیم‌', 'به مقدار لازم', 'به میزان لازم',\n",
    "               'نصف ', 'نصف‌','مقداری', 'به میزان کافی', 'کمتر از', 'دوقاشق']\n",
    "    \n",
    "    while (True):    \n",
    "        spliterIndex = []\n",
    "        for i in spliter:\n",
    "            try:\n",
    "                spliterIndex.append(ing_data.index(i))\n",
    "            except:\n",
    "                spliterIndex.append(9223372036854775807)\n",
    "        endline = 0\n",
    "        try:\n",
    "            endline = ing_data.index(chr(10)) \n",
    "        except:\n",
    "            pass\n",
    "        middle = min(spliterIndex)\n",
    "        \n",
    "        if (middle > endline):\n",
    "            middle = endline\n",
    "        \n",
    "        ing = ing_data[0:middle].strip()\n",
    "        quant = ing_data[middle:endline].strip()\n",
    "        \n",
    "        ing = ing.replace('=', '').strip()\n",
    "        ing = ing.replace(':', '').strip()\n",
    "        \n",
    "        ingredients.append(ing)\n",
    "        quantity.append(quant)\n",
    "        ing_data = ing_data[endline+1:]\n",
    "        if (len(ing_data) == 0):\n",
    "            break\n",
    "            \n",
    "    recipe, span_recipe = find_recipe(ingut ,ending_index)\n",
    "    span_ingredients = findSpanIngredient(ingut, ingredients)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    \n",
    "    return (ingredients, quantity, recipe, span_ingredients, span_recipe, end_time - start_time)\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function is written for the foods with multiple recipees and returns an array which contains each recipee starting index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findRecipeIndex(s: str, ch: str):\n",
    "    indexes = []\n",
    "    first = 0\n",
    "    while (True):\n",
    "        try:\n",
    "            first = s.index(ch, first)\n",
    "            indexes.append(first)\n",
    "            first += 1\n",
    "        except:\n",
    "            break\n",
    "    return indexes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following code block we do the following steps which forms our Main:\n",
    "1. We read our data from the file.\n",
    "2. Then we find how many way we have to cook the selected food.\n",
    "3. Then we iterate each way and we call our functions to find ingredients, quantity of them, recipe, span_ingredients and time.\n",
    "4. We build a dictionary as requested on our homework and we add our data to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Ingredients': ['',\n",
       "   'گوشت گوسفندی با استخوان',\n",
       "   'دنبه',\n",
       "   'لپه',\n",
       "   'پیاز متوسط',\n",
       "   'مغز لیمو عمانی',\n",
       "   'آب گوجه\\u200cفرنگی',\n",
       "   'رب گوجه\\u200cفرنگی',\n",
       "   'سیب\\u200cزمینی',\n",
       "   'نمک و فلفل'],\n",
       "  'quantity': ['',\n",
       "   '۱ کیلو',\n",
       "   '۳۰۰ گرم',\n",
       "   'یک فنجان سرخالی',\n",
       "   'یک عدد',\n",
       "   'یک قاشق سوپخوری',\n",
       "   'یک فنجان',\n",
       "   'یک قاشق سوپخوری',\n",
       "   '۵ عدد',\n",
       "   'به مقدار لازم'],\n",
       "  'recipie': '\\nگوشت و دنبه را پس از شستن ۱۰ قسمت کرده و آن را سرخ کنید تا طلایی شود. پیاز را در روغن سرخ نمایید و لپه خیس\\u200cداده\\u200cشده را به پیاز اضافه کرده و لپه را هم کمی تفت دهید.\\n\\nگوشت سرخ\\u200cشده را با ۴ لیوان آب، زردچوبه، لپه و پیاز داغ با شعله ملایم بپزید. سپس مغز لیمو عمانی را به آبگوشت اضافه کنید. در اواخر طبخ، ۵ تا ۶ عدد سیب\\u200cزمینی را پوست گرفته و با کمی نمک، فلفل و زردچوبه به غذا اضافه می\\u200cکنیم. بعد هم آب گوجه\\u200cفرنگی و رب گوجه\\u200cفرنگی را به آن اضافه کنید. نان سنگک، پیاز، دوغ، سبزی خوردن در کنارش فراموش نشود.',\n",
       "  'span_ingredients': [[41, 73],\n",
       "   [74, 88],\n",
       "   [89, 110],\n",
       "   [111, 130],\n",
       "   [131, 163],\n",
       "   [164, 188],\n",
       "   [189, 219],\n",
       "   [220, 237],\n",
       "   [238, 264]],\n",
       "  'span_recipie': [275, 772],\n",
       "  'time': 0.0010077953338623047}]"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "lines = ''\n",
    "with open('input.txt', 'r',  encoding='utf-8') as f:\n",
    "    lines = f.read()\n",
    "all_dicts = []\n",
    "indexes = findRecipeIndex(lines, 'دستور شمار')\n",
    "if len(indexes) == 0:\n",
    "    indexes.append(0)\n",
    "indexes.append(len(lines))\n",
    "for i in range(len(indexes)-1):\n",
    "    first = indexes[i]\n",
    "    if indexes[i] != 0:\n",
    "        first = lines.find(chr(10),first) + 1\n",
    "    last = indexes[i+1]\n",
    "    ingredients, quantity, recipe, span_ingredients, span_recipe, time_passed = find_ingredients(lines[first:last])\n",
    "    final_dict = {}\n",
    "    final_dict.update({'Ingredients': ingredients})\n",
    "    final_dict.update({'quantity': quantity})\n",
    "    final_dict.update({'recipie': recipe})\n",
    "    final_dict.update({'span_ingredients': span_ingredients})\n",
    "    final_dict.update({'span_recipie': span_recipe})\n",
    "    final_dict.update({'time': time_passed})\n",
    "    all_dicts.append(final_dict)\n",
    "all_dicts"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1baa965d5efe3ac65b79dfc60c0d706280b1da80fedb7760faf2759126c4f253"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
